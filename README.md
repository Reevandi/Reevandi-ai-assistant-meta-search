# AI Assistant with Meta Search Engine

## Project Status
üöß Work in Progress (Ongoing Development)

## Overview
This repository contains an experimental **AI Assistant**
that integrates a **local Large Language Model (LLM)**
with a **meta search engine**.

The project is designed as a learning-focused implementation
to explore local AI inference, web-based interfaces,
and automation using shell scripting.

## Key Features
- Local LLM inference using Ollama
- Lightweight web-based chat interface
- Meta search integration via LibreY
- Automated frontend setup using Bash script
- No external cloud-based AI dependency

## Technology Stack
- Ollama (Local LLM runtime)
- Qwen LLM
- LibreY Meta Search Engine
- Apache HTTP Server
- PHP (Proxy & Backend)
- HTML, CSS, JavaScript (Frontend)

## Automated Setup
An automated Bash script is provided to deploy
the frontend components of the AI assistant.

üìÅ Script location:
1. setup/setup-ai-frontend (only frontend)
2. setup/setup-ai-full
